%---------------------------------------------------------------------
%
%                          Chapter 5
%
%---------------------------------------------------------------------
\renewcommand{\figurename}{Figure}
\chapter{Results}
\label{cap5:results}

\begin{FraseCelebre}
\begin{Frase}
You know the Doctor. You understand him. You will predict his actions.
\end{Frase}
\begin{Fuente}
DALEK. Doctor Who. \textit{The Parting of the Ways}.
\end{Fuente}
\end{FraseCelebre}

This Chapter reports all the experiments thas have been conducted, from the first stage using the initial (and unbalanced) log file, to the last in where we have used separated files for training and testing (see Section \ref{cap4:sec:traintest}). At the beggining, and given that we were working with rules, the initial log file (with the entries that have been labelled as allowed or denied) was tested following a \textit{cross-validation} partition, with all the possible rule and tree classifiers given in Weka. With this initial ranking, we took the five classifiers that obtained the best results and continue testing with all the rest of the partitions. Also, for each section, best results are commented, and therefore conclusions will be given in the next Chapter.

%-------------------------------------------------------------------
\section{Experiment results}
%-------------------------------------------------------------------
\label{cap5:sec:exp}

As explained in Section \ref{cap4:sec:Weka}, an initial group of experiments was conducted and te results can be consulted at Table \ref{tabresults_todos}. The top five was formed by the classifiers: J48, Random Forest, REP Tree, NNge, and PART, plus Naïve Bayes as a reference. These five classifiers were then training and tested with both training and test files, as explained in Section \ref{cap4:sec:traintest}. First results can be found in Table \ref{tabresults_nobalan} \footnote{All result tables are publicly accessible through the following link: \url{https://drive.google.com/folderview?id=0B0Rvxfh8NwQRMi1RYU9uT3FmQzg&usp=sharing}}. Results in that Table were obtained after a balancing process applied over the initial file, as explained in Section \ref{cap4:sec:traintest}. Then, when performing \textit{undersampling}, half of the total of the `allowed' patterns were randomly removed, and when \textit{oversampling} was applied, each of the the `denied' patterns were repeated till the total of `denied' patterns was the same as `allowed'.

\begin{table}[htpb]
\centering 
{\small
\begin{tabular}{|l|c|c|}
\cline{2-3}
\multicolumn{1}{l|}{} & Undersampling & Oversampling \\ 
\hline
Naïve Bayes & 91.02 $\pm$ 0.10 & 91.77 \\ 
\cline{1-1}
Conjunctive Rule & 60.00 $\pm$ 0.14 & 60.02 \\ 
\cline{1-1}
Decision Table & 94.31 $\pm$ 0.20 & 90.29 \\ 
\cline{1-1}
DTNB & 94.92 $\pm$ 0.14 & 95.65 \\ 
\cline{1-1}
JRip & 90.03 $\pm$ 0.07 & 92.47 \\ 
\cline{1-1}
NNge & \textbf{96.47} $\pm$ 0.02 & \textbf{98.76} \\ 
\cline{1-1}
One R & 93.53 $\pm$ 0.08 & 93.70 \\ 
\cline{1-1}
PART & \textbf{96.35} $\pm$ 0.09 & \textbf{97.54} \\ 
\cline{1-1}
Ridor & 86.60 $\pm$ 0.55 & 89.87 \\ 
\cline{1-1}
Zero R & 51.22 $\pm$ 0.16 & 51.26 \\ 
\cline{1-1}
AD Tree & 77.65 $\pm$ 0.08 & 77.68 \\ 
\cline{1-1}
Decision Stump & 60.00 $\pm$ 0.14 & 60.02 \\ 
\cline{1-1}
J48 & \textbf{96.99} $\pm$ 0.04 & \textbf{98.00} \\ 
\cline{1-1}
LAD Tree & 78.93 $\pm$ 1.71 & 79.97 \\ 
\cline{1-1}
Random Forest & \textbf{96.94} $\pm$ 0.07 & \textbf{98.84} \\ 
\cline{1-1}
Random Tree & 95.59 $\pm$ 0.40 & 98.35 \\ 
\cline{1-1}
REP Tree & \textbf{96.74} $\pm$ 0.04 & \textbf{97.67} \\ 
\hline
\end{tabular}
}
\caption[Global classification methods ranking. Classifiers are trained and tested by crossvalidation.]{\label{tabresults_todos} Results of all tested classification methods on balanced data. The best ones are marked in boldface.}
\end{table}

\begin{table*}[htpb]
\centering
{\small
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{80\% Training - 20\% Test} & \multicolumn{2}{c|}{90\% Training - 10\% Test} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & Random (mean) & Sequential & Random (mean) & Sequential \\ 
\hline
Naïve Bayes & 91.60 $\pm$ 1.25 & 85.53 & 92.89 $\pm$ 0.12 & 83.84 \\ 
\cline{1-1}
J48 & 97.56 $\pm$ 0.20 & 88.48 & \textbf{97.70} $\pm$ \textbf{0.15} & 82.28 \\ 
\cline{1-1}
Random Forest & \textbf{97.68} $\pm$ \textbf{0.20} & \textbf{89.77} & 97.63 $\pm$ 0.13 & 82.59 \\ 
\cline{1-1}
REP Tree & 97.47 $\pm$ 0.11 & 88.34 & 97.57 $\pm$ 0.01 & 83.20 \\ 
\cline{1-1}
NNge & 97.23 $\pm$ 0.10 & 84.41 & 97.38 $\pm$ 0.36 & 80.34 \\ 
\cline{1-1}
PART & 97.06 $\pm$ 0.19 & 89.11 & 97.40 $\pm$ 0.16 & \textbf{84.17} \\ 
\hline
\end{tabular}
}
\caption[Percentage of correctly classified patterns for unbalanced data.]{\label{tabresults_nobalan} Percentage of correctly classified patterns for unbalanced data. The best ones are marked in boldface.}
\end{table*}

As it can be seen, all five methods achieved a high performance classifying in the right way the test dataset. The given numbers are the mean taken from three genetations of undersampled files from the original, due to the \textit{random} nature of the process. Also, these results are not like this by chance, as shown by a low standard deviation.

Next step described in Section \ref{cap4:sec:traintest} was, then, to separate the original file into training and test files. The results are depicted in Table \ref{tabresults_nobalan}. Obtained results for the first division, 80\% of the original dataset taken for training, and the 20\% for testing the classifiers, are quite good (\textit{Random Forest} reached a 97.68\% of accuracy with a standard deviation of 0.2). As was expected, the results from the 90\%-10\% division were slightly better, and due to this a more aggressive division was executed in the following experiments so the methods can be really proved with much less training data.

What matters to the results of the experiments made with the sequential data, they are worse than the obtained from the random data, but they are still good ($>$ 85\%). This is due to the occurrence of new patterns from a certain time (maybe there are some requests that are made just at one specific time in a day, or in settled days), and then there is no sufficient similarity between the training data and the classifying of the test data set may fail. The loss of 5 to 6 points in the results of the 90\%-10\% division is the first unexpected or unlogical result of the experiments, but they also reinforce the previous theory.

The technique that lightly stands out over the others is \textit{Random Forest}, being the best in almost every case, even in the experiments with the most complex sequential divisions. Also, \textit{J48} reached high accuracies with a lesser standard deviation. In general, all the obtained results present robustness as can be seen in the standard deviations.

For its part, results obtained from unbalanced data are shown in Table \ref{tabresults_balan}. As explained in Section \ref{cap4:sec:traintest}, the corresponding to the random partitions come from the mean of three blocks of experiments, and so are specified the standard deviations. The Table illustrates two segments of results, obtained from the undersampled data and from the oversampled data. For each one, the 90\%-10\% and 80\%-20\% divisions were also made. We distinguish the results depending on:

\begin{description}
  \item[Applying Undersampling] In comparison with those results from Table \ref{tabresults_nobalan}, these go down one point (in the case of randomly made divisions) to six points (sequential divisions). The reason why this happens is that when randomly removing ALLOW patterns, we are really losing information, i. e. key patterns that could be decisive in a good classification of a certain set of test patterns. 
  \item[Applying Oversampling] Here we have duplicated the DENY patterns so their number could be up to that of the ALLOW patterns. However, it does not work as well as in other approaches which uses numerical computations for creating the new patterns to include in the minority class. Consequently, the results have been decreased.
\end{description}

\begin{figure}[htb]
\centering
\subfloat[80\% for training, \%20 for testing]{
\small
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{4}{c|}{80\% Training - 20\% Test} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{Undersampling} & \multicolumn{2}{c|}{Oversampling} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & Rand (mean) & Sequential & Rand (mean) & Sequential \\ 
\hline
Naïve Bayes & 91.30 $\pm$ 0.20 & 84.94 & 91.74 $\pm$ 0.13 & 85.43 \\ 
\cline{1-1}
J48 & \textbf{97.05} $\pm$ \textbf{0.25} & 84.29 & \textbf{97.40} $\pm$ \textbf{0.03} & 85.66 \\ 
\cline{1-1}
Random Forest & 96.61 $\pm$ 0.17 & \textbf{88.59} & 97.16 $\pm$ 0.19 & \textbf{89.03} \\ 
\cline{1-1}
REP Tree & 96.52 $\pm$ 0.13 & 85.54 & 97.13 $\pm$ 0.25 & 85.41 \\ 
\cline{1-1}
NNge & 96.56 $\pm$ 0.42 & 85.28 & 96.90 $\pm$ 0.28 & 83.46 \\ 
\cline{1-1}
PART & 96.19 $\pm$ 0.14 & 85.16 & 96.82 $\pm$ 0.09 & 84.50 \\ 
\hline
\end{tabular}
}

\subfloat[90\% for tranining, 10\% for testing]{
\small
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{4}{c|}{90\% Training - 10\% Test} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{Undersampling} & \multicolumn{2}{c|}{Oversampling} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & Rand (mean) & Sequential & Rand (mean) & Sequential \\ 
\hline
Naïve Bayes & 91.18 $\pm$ 0.16 & \textbf{82.35} & \textbf{91.77} $\pm$ 0.28 & \textbf{81.81} \\ 
\cline{1-1}
J48 & 96.85 $\pm$ 0.35 & 76.44 & 97.37 $\pm$ 0.06 & 74.24 \\ 
\cline{1-1}
Random Forest & \textbf{96.99} $\pm$ \textbf{0.13} & 79.98 & 97.25 $\pm$ 0.33 & 81.33 \\ 
\cline{1-1}
REP Tree & 96.55 $\pm$ 0.10 & 77.65 & 97.14 $\pm$ 0.09 & 76.81 \\ 
\cline{1-1}
NNge & 96.33 $\pm$ 0.05 & 81.93 & 96.91 $\pm$ 0.06 & 78.73 \\ 
\cline{1-1}
PART & 96.09 $\pm$ 0.10 & 79.70 & 96.68 $\pm$ 0.11 & 78.16 \\ 
\hline
\end{tabular}
}
\caption[Percentage of correctly classified patterns for balanced data, training and testing with different files.]{Percentage of correctly classified patterns for balanced data (undersampling and oversampling). (a) 80\% for training, \%20 for testing. (b) 90\% for tranining, 10\% for testing. Best results are marked in boldface. \label{tabresults_balan}}
\end{figure}

It is noticeable in both cases that taking the data in a sequential way, instead of randomly, lower the results. It is clear that due to the fact that performing undersampling some patterns are lost while in the case of oversampling they all remain, \textit{undersampling results} are better. Then, in this case the algorithm with best performance is \textit{J48}, though \textit{Random Forest} follows its results very closely in random datasets processing, and \textit{REP Tree}, which is better than the rest when working with sequential data. Nevertheless, generally speaking and given the aforementioned reasons, performing data balancing methods yields worse results.

%-------------------------------------------------------------------
\subsection{Removal of duplicated requests}
%-------------------------------------------------------------------
\label{cap5:sec:exp:repurls}

After performing the step 2 that is depicted in Figure \ref{fig:work_diagram_2}, a whole new ranking of classification performance was created, in order to see if the new situation has some influence on the results. However, Table  \ref{tab:gobalrank_repurls} shows that the best results are from the same classifiers, with slightly difference when performing oversampling, where \textit{Random Tree} was better than \textit{REP Tree} but less than one point.

\begin{table}[htpb]
\centering
{\small
\begin{tabular}{|l|c|c|c|}
\cline{2-4}
\multicolumn{1}{l|}{} & Unbalanced & Undersampling & Oversampling \\
\hline
Naïve Bayes & 92.30 & 90.77 $\pm$ 0.06 & 91.77 \\
\cline{1-1}
Conjunctive Rule & 73.31 & 59.53 $\pm$ 0.15 & 60.02 \\
\cline{1-1}
Decision Table & 95.21 & 93.73 $\pm$ 0.18 & 90.29 \\
\cline{1-1}
DTNB & 95.55 & 94.75 $\pm$ 0.07 & 95.65 \\
\cline{1-1}
JRip & 92.95 & 89.64 $\pm$ 0.32 & 92.47 \\
\cline{1-1}
NNge & \textbf{97.18} & \textbf{96.33 $\pm$ 0.14} & \textbf{98.76} \\
\cline{1-1}
One R & 94.86 & 93.53 $\pm$ 0.04 & 93.70 \\
\cline{1-1}
PART & \textbf{97.41} & \textbf{96.32 $\pm$ 0.10} & \textbf{97.54} \\
\cline{1-1}
Ridor & 89.21 & 86.19 $\pm$ 0.79 & 89.87 \\
\cline{1-1}
Zero R & 68.14 & 51.68 $\pm$ 0.17 & 51.26 \\
\cline{1-1}
AD Tree & 85.23 & 78.01 $\pm$ 0.10 & 77.68 \\
\cline{1-1}
Decision Stump & 73.31 & 59.53 $\pm$ 0.15 & 60.02 \\
\cline{1-1}
J48 & \textbf{97.37} & \textbf{96.65 $\pm$ 0.04} & \textbf{98.00} \\
\cline{1-1}
LAD Tree & 86.87 & 80.24 $\pm$ 0.04 & 79.97 \\
\cline{1-1}
Random Forest & \textbf{97.57} & \textbf{96.75 $\pm$ 0.05} & \textbf{98.84} \\
\cline{1-1}
Random Tree & 96.11 & 95.45 $\pm$ 0.66 & \textbf{98.35} \\
\cline{1-1}
REP Tree & \textbf{97.32} & \textbf{96.38 $\pm$ 0.07} & 97.67 \\
\hline
\end{tabular}
}
\caption[Global classification methods ranking after the removal of entries that coul lead to missclassification.]{\label{tab:gobalrank_repurls} Results of all tested classification methods on unbalanced and balanced data, after the repeated requests have been removed. The best ones are marked in boldface.}
\end{table}

The process is again the same, and the results are displayed in Tables \ref{tab:repurl_unb_traintest} (a) and (b). We can see that the results are slightly worse than the ones obtained in step 1, but they are still good, and definitely better than Naïve Bayes, our result reference. It is not a surprise that, again, results for files with the patterns taken consecutively lower significantly. As previously, this is because the possible loss of information. Best results are obtained by both \textit{Random Forest} and \textit{REP Tree} classifiers, with a 96\% of accuracy.

\begin{figure}[htb]
\centering
\subfloat[80\% for training, \%20 for testing, and 90\% for tranining, 10\% for testing]{
\small
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{80\% Training - 20\% Test} & \multicolumn{2}{c|}{90\% Training - 10\% Test} \\ 
\cline{2-5}
\multicolumn{1}{l|}{} & Random (mean) & Sequential & Random (mean) & Sequential \\ 
\hline
Naïve Bayes & 93.01 $\pm$ 0.32 & 82.61 & 93.09 $\pm$ 0.91 & 83.04 \\ 
\cline{1-1}
Random Forest & \textbf{96.97} $\pm$ \textbf{0.47} & \textbf{91.03} & \textbf{96.79} $\pm$ \textbf{0.97} & 80.60 \\ 
\cline{1-1}
J48 & 96.90 $\pm$ 0.26 & 87.78 & 96.50 $\pm$ 1.00 & 84.49 \\ 
\cline{1-1}
NNge & 96.21 $\pm$ 0.28 & 81.17 & 96.11 $\pm$ 1.13 & 81.92 \\ 
\cline{1-1}
REP Tree & \textbf{96.97} $\pm$ \textbf{0.40} & 87.75 & 96.62 $\pm$ 0.87 & \textbf{85.57} \\ 
\cline{1-1}
PART & 96.84 $\pm$ 0.18 & 86.68 & 96.55 $\pm$ 0.87 & 83.61 \\ 
\hline
\end{tabular}
}

\subfloat[60\% for tranining, 40\% for testing]{
\small
\begin{tabular}{|l|c|c|}
\cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{60\% Training - 40\% Test} \\ 
\cline{2-3}
\multicolumn{1}{l|}{} & Random (mean) & Sequential\\ 
\hline
Naïve Bayes & 92.76 $\pm$ 1.34 & 77.74 \\ 
\cline{1-1}
Random Forest & \textbf{96.45} $\pm$ \textbf{0.67} & 87.50 \\ 
\cline{1-1}
J48 & 96.44 $\pm$ 0.19 & 87.42 \\ 
\cline{1-1}
NNge & 95.98 $\pm$ 0.34 & 84.73 \\ 
\cline{1-1}
REP Tree & 96.41 $\pm$ 0.27 & \textbf{88.91} \\ 
\cline{1-1}
PART & 96.05 $\pm$ 0.45 & 81.29 \\ 
\hline
\end{tabular}
}
\caption[Correctly classified patterns for unbalanced data after the removal of entries that coul lead to missclassification.]{Percentage of correctly classified patterns for unbalanced data, after after the removal of entries that coul lead to missclassification.. (a) 80\% for training, \%20 for testing, and 90\% for tranining, 10\% for testing. (b) 60\% for tranining, 40\% for testing. Best results are marked in boldface. \label{tab:repurl_unb_traintest}}
\end{figure}

%-------------------------------------------------------------------
\subsection{Enhancing the creation of training and test files}
%-------------------------------------------------------------------
\label{cap5:sec:exp:coredomains}

The last step taken in this research was to try to better separate the patterns from the initial file. Thus, we tried to avoid possible classification errors by assuring that entries with the same core domain end in the same file (either for training o testing) (see Figure \ref{fig:work_diagram_2}).

It must be pointed out that, for the moment, there are no generations of training and test files with the patterns taken consecutively. The reason for this can be seen also in Table \ref{tab:coredom_stats}: taking into account this way of separating the data, when a certain log entry happens to be placed in the training, or testing, file, all the others which share the same \ac{URL} core domain, will follow to the same file, and therefore is impossible to reach the desired file distribution.

Furthermore, taking a look at the results in Table \ref{tab:coredom_unb_traintest}, they are by far the worst we obtained. It seems that a lot of information is lost by performing this step. These Tables show a comparison between the tested classifiers during this process. It can be seen that the best classifiers are \textit{J48} and \textit{REP Tree} (between 70.69\% and 74.72\% of accuracy).

\begin{figure}[htb]
\centering
\subfloat[Training and Test files, random, 1st generation]{
\small
\begin{tabular}[t]{|l|c|c|c|c|}
\hline
File &             Total & Allow & Deny & \% of Original \\
\hline
Original &            38619 & 26318 & 12301 & 100 \\
\hline
Training 80\% &  30466 & 20169 & 10297 & 78.79  \\
\hline
Test 20\% &           8153 & 6149 & 2004 & 21.11  \\
\hline
Training 90\% &  29964 & 20454 & 9510 & 77.59  \\
\hline
Test 10\% &           8655 & 5864 & 2791 & 22.41  \\
\hline
Training 60\% &  19272 & 13705 & 5567 & 49.90  \\
\hline
Test 40\% &           19347 & 12613 & 6734 & 50.10 \\
\hline
\end{tabular}
}

\subfloat[Training and Test files, random, 2nd generation]{
\small
\begin{tabular}[t]{|l|c|c|c|c|}
\hline
File &             Total & Allow & Deny & \% of Original \\
\hline
Original &            38619 & 26318 & 12301 & 100 \\
\hline
Training 80\% &  28368 & 18206 & 10162 & 73.46 \\
\hline
Test 20\% &           10251 & 8112 & 2139 & 26.54 \\
\hline
Training 90\% &  31463 & 20776 & 10687 & 81.47 \\
\hline
Test 10\% &           7156 & 5542 & 1614 & 18.53 \\
\hline
Training 60\% &  21945 & 14814 & 7131 & 56.82 \\
\hline
Test 40\% &           16674 & 11504 & 5170 & 43.18 \\
\hline
\end{tabular}
}

\subfloat[Training and Test files, random, 3rd generation]{
\small
\begin{tabular}[t]{|l|c|c|c|c|}
\hline
File &             Total & Allow & Deny & \% of Original \\
\hline
Original &            38619 & 26318 & 12301 & 100 \\
\hline
Training 80\% &  31068 & 21862 & 9206 & 80.45 \\
\hline
Test 20\% &           7551 & 4456 & 3095 & 19.55 \\
\hline
Training 90\% &  32034 & 21119 & 10915 & 82.95 \\
\hline
Test 10\% &           6585 & 5199 & 1386 & 17.05 \\
\hline
Training 60\% &  23337 & 14416 & 8921 & 60.43 \\
\hline
Test 40\% &           15282 & 11902 & 3380 & 39.57 \\
\hline
\end{tabular}
}
\caption[Statistics of the files created after the removal of entries that coul lead to missclassification.]{\label{tab:coredom_stats} Statistics of the files created after the duplicated connections were removed. It can be seen that after the partitions, the ratio between allows and denies remains the same, unbalanced. (a), (b), and (c) Three generations of files generated by randomly taking patterns from the original file. (d) Files generated by consecutively taking patterns from the original file.}
\end{figure}


\begin{table}[htpb]
\centering
{\small
\begin{tabular}{|l|c|c|c|}
\hline
\multicolumn{1}{|l|}{Percentage training \& test} & \multicolumn{1}{c|}{80\% - 20\%} & \multicolumn{1}{c|}{90\% - 10\%} & \multicolumn{1}{c|}{60\% - 40\%} \\ 
\hline
Naïve Bayes & 48.67 $\pm$ 11.70 & 44.99 $\pm$ 18.59 & 44.58 $\pm$ 10.73 \\ 
\cline{1-1}
Random Forest & 67.48 $\pm$ 9.61 & 74.21 $\pm$ 6.01 & 70.29 $\pm$ 5.06 \\ 
\cline{1-1}
J48 & \textbf{71.19} $\pm$ \textbf{10.71} & \textbf{74.72} $\pm$ \textbf{6.08} & \textbf{70.69} $\pm$ \textbf{6.51} \\ 
\cline{1-1}
NNge & 58.19 $\pm$ 4.18 & 65.82 $\pm$ 5.70 & 53.77 $\pm$ 5.59 \\ 
\cline{1-1}
REP Tree & \textbf{71.19} $\pm$ \textbf{10.71} & \textbf{74.72} $\pm$ \textbf{6.08} & \textbf{70.69} $\pm$ \textbf{6.51} \\ 
\cline{1-1}
PART & 68.37 $\pm$ 13.36 & 67.52 $\pm$ 9.60 & 64.23 $\pm$ 5.82 \\ 
\hline
\end{tabular}
}
\caption[Correctly classified patterns for unbalanced data after assuring that same values for a feature of the URL go all to training or testing.]{\label{tab:coredom_unb_traintest} Percentage of correctly classified patterns for unbalanced data after assuring that same values for a feature of the URL go all to training or testing. There are three different sets of files: 80\% for training, \%20 for testing; 90\% for tranining, 10\% for testing; and 60\% for tranining, 40\% for testing. Best results are marked in boldface.}
\end{table}

% Al final he quitado las figuras porque total, estaban hechas para ponerlas en Hamgurgo. Si me da tiempo las hago bien y las pongo.

%-------------------------------------------------------------------
\subsection{Filtering the features of the URL}
%-------------------------------------------------------------------
\label{cap5:sec:exp:tlds}

Last step explained in Section \ref{cap4:sec:traintest}, was the repetition of the experiments done at the beggining, but studying what would it happen if we trained the classifiers including the \ac{TLD} feature of the \ac{URL}, but excluding the core domaind used until now. Tables \ref{tab:tld_unb_traintest}, \ref{tab:tld_und_traintest}, and \ref{tab:tld_ov_traintest} show the results of this whole new set of experiments. We focused directly in testing the known-top five of classifiers, plus Naïve Bayes, with partitions for training and testing, including the 60\% for training and 40\% for testing, to see the ability for generalisation of the classifiers. Also, as we had obtained the best results for the partitions made randomly, we excluded sequential partition in these experiments, in order to focus in the best results.

\begin{table}[htpb]
\centering
{\small
\begin{tabular}{|l|c|c|c|}
\hline
\multicolumn{1}{|l|}{Percentage training \& test} & \multicolumn{1}{c|}{80\% - 20\%} & \multicolumn{1}{c|}{90\% - 10\%} & \multicolumn{1}{c|}{60\% - 40\%} \\ 
\hline
Naïve Bayes & 81.56 $\pm$ 2.68 & 79.68 $\pm$ 0.67 & 79.85 $\pm$ 0.77 \\ 
\cline{1-1}
Random Forest & 95.42 $\pm$ 0.32 & \textbf{95.69} $\pm$ \textbf{0.27} & \textbf{95.16} $\pm$ \textbf{0.22} \\ 
\cline{1-1}
J48 & 95.00 $\pm$ 0.27 & 94.89 $\pm$ 0.15 & 93.97 $\pm$ 0.15 \\ 
\cline{1-1}
NNge & \textbf{95.47} $\pm$ \textbf{0.09} & 94.50 $\pm$ 0.42 & 93.97 $\pm$ 0.22 \\ 
\cline{1-1}
REP Tree & 94.20 $\pm$ 0.30 & 93.95 $\pm$ 0.16 & 93.12 $\pm$ 0.26 \\ 
\cline{1-1}
PART & 94.77 $\pm$ 0.12 & 95.02 $\pm$ 0.08 & 94.13 $\pm$ 0.11 \\ 
\hline
\end{tabular}
}
\caption[Correctly classified patterns for unbalanced data after the core domain feature was removed for classification, and TLD was added.]{\label{tab:tld_unb_traintest} Percentage of correctly classified patterns for unbalanced data the core domain feature was removed for classification, and TLD was added. There are three different sets of files: 80\% for training, \%20 for testing; 90\% for tranining, 10\% for testing; and 60\% for tranining, 40\% for testing. Best results are marked in boldface.}
\end{table}

\begin{table}[htpb]
\centering
{\small
\begin{tabular}{|l|c|c|c|}
\hline
\multicolumn{1}{|l|}{Percentage training \& test} & \multicolumn{1}{c|}{80\% - 20\%} & \multicolumn{1}{c|}{90\% - 10\%} & \multicolumn{1}{c|}{60\% - 40\%} \\ 
\hline
Naïve Bayes & 79.70 $\pm$ 0.25 & 79.96 $\pm$ 0.72 & 79.43 $\pm$ 1.72 \\ 
\cline{1-1}
Random Forest & \textbf{94.01} $\pm$ \textbf{0.28} & \textbf{95.46} $\pm$ \textbf{1.73} & \textbf{93.32} $\pm$ \textbf{0.11} \\ 
\cline{1-1}
J48 & 92.93 $\pm$ 0.37 & 93.23 $\pm$ 0.14 & 92.15 $\pm$ 0.39 \\ 
\cline{1-1}
NNge & 93.07 $\pm$ 0.23 & 93.28 $\pm$ 0.26 & 92.51 $\pm$ 0.14 \\ 
\cline{1-1}
REP Tree & 91.80 $\pm$ 0.24 & 91.90 $\pm$ 0.35 & 90.94 $\pm$ 0.16 \\ 
\cline{1-1}
PART & 93.03 $\pm$ 0.09 & 94.46 $\pm$ 1.69 & 92.28 $\pm$ 0.49 \\ 
\hline
\end{tabular}
}
\caption[Correctly classified patterns for balanced data (undersampling technique) after the core domain feature was removed for classification, and TLD was added.]{\label{tab:tld_und_traintest} Percentage of correctly classified patterns for balanced data (with undersampling technique) after the core domain feature was removed for classification, and TLD was added. There are three different sets of files: 80\% for training, \%20 for testing; 90\% for tranining, 10\% for testing; and 60\% for tranining, 40\% for testing. Best results are marked in boldface.}
\end{table}

\begin{table}[htpb]
\centering
{\small
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|l|}{Percentage training \& test} & \multicolumn{1}{c|}{80\% - 20\%} & \multicolumn{1}{c|}{90\% - 10\%} & \multicolumn{1}{c|}{60\% - 40\%} \\ 
\hline
Naïve Bayes & 79.57 $\pm$ 0.98 & 79.87 $\pm$ 0.20 & 79.49 $\pm$ 0.88 \\ 
\cline{1-1}
Random Forest & \textbf{97.09} $\pm$ \textbf{0.06} & \textbf{97.90} $\pm$ \textbf{0.22} & \textbf{96.24} $\pm$ \textbf{0.14} \\ 
\cline{1-1}
J48 & 95.77 $\pm$ 0.42 & 96.25 $\pm$ 0.17 & 94.92 $\pm$ 0.12 \\ 
\cline{1-1}
NNge & 96.82 $\pm$ 0.27 & 97.66 $\pm$ 0.25 & 95.78 $\pm$ 0.16 \\ 
\cline{1-1}
REP Tree & 94.63 $\pm$ 0.27 & 95.23 $\pm$ 0.34 & 93.80 $\pm$ 0.09 \\ 
\cline{1-1}
PART & 95.73 $\pm$ 0.30 & 96.12 $\pm$ 0.05 & 94.86 $\pm$ 0.16 \\ 
\hline
\end{tabular}
}
\caption[Correctly classified patterns for balanced data (oversampling technique) after the core domain feature was removed for classification, and TLD was added.]{\label{tab:tld_ov_traintest} Percentage of correctly classified patterns for balanced data (with oversampling technique) after the step 4. There are three different sets of files: 80\% for training, \%20 for testing; 90\% for tranining, 10\% for testing; and 60\% for tranining, 40\% for testing. Best results are marked in boldface.}
\end{table}

This way, Table \ref{tab:tld_und_traintest} shows that \textit{Random Forest} is again the best classifier (95.42\% of accuracy in the separation 80\% for training, \%20 for testing, even though \textit{NNge} was the best but just in 0.05 points). The importat point derived from these results is that the accuracy percentages do not lower after not taking into account the core domain feature of the \ac{URL}, so maybe the classification is not that dependant on it.

%-------------------------------------------------------------------
\section{Rules obtained, a study case}
%-------------------------------------------------------------------
\label{cap5:sec:rule}

With regard to the obtained rules/trees, we want to remark that the majority are based on the \ac{URL} in order to discriminate between the two classes, however we also found several ones which consider variables/features different of this to make the decision. For instance:\\

\begin{verbatim}
IF server_or_cache_address = "90.84.53.17" 
THEN DENY

IF server_or_cache_address = "173.194.78.103" 
THEN ALLOW

IF content_type = 
 "application/vnd.google.safebrowsing-update" 
THEN DENY

IF server_or_cache_address = "173.194.78.94" 
AND content_type_MCT = "text"
AND content_type = "text/html"
AND http_reply_code = "200"
AND bytes > 772
THEN ALLOW

IF server_or_cache_address = "173.194.34.225"
AND http_method = "GET"
AND duration_milliseconds > 52
THEN ALLOW

IF server_or_cache_address = "90.84.53.49"
AND time <= 33758000
THEN ALLOW
\end{verbatim}

These rules are the most interesting for our purposes, since they are somehow independent of the \ac{URL} to which the client requests to access. Thus, it would be potentially possible to allow or deny the access to unknown \ac{URL}s just taking into account some parameters of the session.

Of course, some of these features depend on the session itself, i.e. they will be computed after the session is over, but the idea in that case would be 'to refine' somehow the existing set of \ac{URL}s in the White List.
Thus, when a client requests access to a Whitelisted \ac{URL}, this will be allow, but after the session is over, and depending on the obtained values, and on one of these classifiers, the \ac{URL} could be labelled as DENIED for further requests.
This could be a useful decision-aid tool for the CSO in a company, for instance.
In case that the features considered in the rule can be known in advance, such as \texttt{http\_method}, or \texttt{server\_or\_cache\_address}, for example, the decision could be made in real-time, and thus, a granted \ac{URL} (Whitelisted) could be DENIED or the other way round.


%The tree-based methods also yield several useful branches in this sense, but they have not been plotted here because of the difficulty for showing/visualizing them properly.



% Variable local para emacs, para  que encuentre el fichero maestro de
% compilación y funcionen mejor algunas teclas rápidas de AucTeX
%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Tesis.tex"
%%% End:

% Debes añadir una sección donde digas qué es lo que funciona mejor y
% por qué - JJ
