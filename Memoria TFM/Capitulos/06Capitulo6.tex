%---------------------------------------------------------------------
%
%                          Chapter 6
%
%---------------------------------------------------------------------
\renewcommand{\figurename}{Figure}
\chapter{Conclusions and future work}
\label{cap6:conclusions}

\begin{FraseCelebre}
\begin{Frase}
Whatever happens today, will change future events, create its own timeline, its own reality. The future pivots around you, here, now. So do good, for humanity, and for Earth.
\end{Frase}
\begin{Fuente}
11th Doctor to Amy. Doctor Who. \textit{Cold Blood}.
\end{Fuente}
\end{FraseCelebre}

%-------------------------------------------------------------------
\section{Discussion}
%-------------------------------------------------------------------
\label{cap6:sec:discussion}

During the elaboration of this Master Thesis, a set of classification methods have been applied in order to perform a decision process inside a company, according to some predefined corporate security policies. This decision is focused on allowing or denying \ac{URL} access requests, but just considering previous decisions on similar requests, not by having specific rules in a White/Black List defined including those \ac{URL}s. Thus, the proposed method could allow or deny an access to a \ac{URL}, based in additional features rather than just the specific \ac{URL} string or its lexical properties. This would be very useful since new \ac{URL}s could be automatically `Whitelisted', or `Blacklisted', just depending on some of the connection parameters, such as the \texttt{content\_type} of the response or the \texttt{IP} of the client which makes the request.

To this aim, we have started from a big dataset (100000 patterns) about employees'  \ac{URL} sessions information (Section \ref{cap3:sec:log}), and considering a set of \ac{URL} access permissions (Section \ref{cap3:sec:rules}), we have composed a labelled dataset (more than 57000 labelled patterns, see Table \ref{tab_stats1}). Over that set of data, we have tested several classification methods, after some data balancing techniques have been applied. Then, the top five have been deeply proved over several training and test divisions (Section \ref{cap4:sec:traintest}), and with two methods: using sequential patterns (consecutive \ac{URL} accesses), and taking them in a randomly way.

We have performed experiments following a series of steps (see Figures \ref{fig:work_diagram_1} and \ref{fig:work_diagram_2}), and studying how the results changed and why.

The results shown, at first step, that classification accuracies are
between 95\% and 97\%, even when using the unbalanced datasets
(Section \ref{cap5:sec:exp}). However, they have been diminished
because of the possible loss of data that comes from performing an
undersampling (removing patterns) method; or taking the training and
the data sets in a sequential way from the main log file, due to the
fact that certain \ac{URL} requests can be made only at a certain
time. This also happened in the experiments from steps two and three,
because the involved the removal of even more patterns (duplicated
requests, and avoiding repetition of the same core domain feature of
the \ac{URL}s in the same training/test file), and more loss of
information. The last experiments shown accuracies not higher than
74\%. Despite of that, we can conclude that the approach has been
successful and it would be a useful tool in an enterprise.

% This is not a discussion, it's a description of the results. You
% should discuss why results are so bad or so good, why the methods
% used have happened to work or not, compare maybe with other methods,
% discuss whether these results are so because of preprocessing or the
% method... discussion is very important - JJ

%-------------------------------------------------------------------
\section{Future Work}
%-------------------------------------------------------------------
\label{cap6:sec:future}

Future lines of work include conducting a deeper set of experiments trying to test the generalisation power of the method, maybe considering bigger data divisions, bigger data sets (from a whole day or working day), or adding some kind of `noise'  to the dataset. One of the future steps to follow will be to perform experiments with the other two datasets (one bigger of 5 million entries, and a 1 million entries subset of it) described in Section \ref{cap3:sec:log}, and obtained almost at the end of this research work.

So that, considering the good classification results obtained, another next step could be the application of these methods in the real system from which data was gathered, counting with the opinion of expert \ac{CSO}s, in order to know the real value of the proposal.
The study of other classification methods could be another research
branch, along with the implementation of a Genetic Programming
approach, which could deal with the imbalance problem using a
modification of the cost associated with  misclassifying, could be done (as the authors did in \citep{cost_adjustment_07}).

Finally, as found by reviewing the State of the Art (see Section \ref{cap2:sec:url}), the more features are extracted from the connection requests, the better results are obtained \citep{Ma_Url11}. Then, we will also extract additional information from the \ac{URL} string, than could be transformed into additional features that could be more discriminative than the current set. Moreover, a data process involving summarizing data about sessions (such as number of requests per client, or average time connection) will be also considered.


% Variable local para emacs, para  que encuentre el fichero maestro de
% compilación y funcionen mejor algunas teclas rápidas de AucTeX
%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Tesis.tex"
%%% End:
